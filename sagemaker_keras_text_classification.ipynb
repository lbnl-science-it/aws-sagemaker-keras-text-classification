{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification Using Keras & TensorFlow on Amazon SageMaker\n",
    "\n",
    "Full lab guide can be found here: https://github.com/aws-samples/amazon-sagemaker-keras-text-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>URL</th>\n",
       "      <th>PUBLISHER</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>STORY</th>\n",
       "      <th>HOSTNAME</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fed official says weak data caused by weather,...</td>\n",
       "      <td>http://www.latimes.com/business/money/la-fi-mo...</td>\n",
       "      <td>Los Angeles Times</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.latimes.com</td>\n",
       "      <td>1394470370698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fed's Charles Plosser sees high bar for change...</td>\n",
       "      <td>http://www.livemint.com/Politics/H2EvwJSK2VE6O...</td>\n",
       "      <td>Livemint</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.livemint.com</td>\n",
       "      <td>1394470371207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US open: Stocks fall after Fed official hints ...</td>\n",
       "      <td>http://www.ifamagazine.com/news/us-open-stocks...</td>\n",
       "      <td>IFA Magazine</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.ifamagazine.com</td>\n",
       "      <td>1394470371550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fed risks falling 'behind the curve', Charles ...</td>\n",
       "      <td>http://www.ifamagazine.com/news/fed-risks-fall...</td>\n",
       "      <td>IFA Magazine</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.ifamagazine.com</td>\n",
       "      <td>1394470371793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fed's Plosser: Nasty Weather Has Curbed Job Gr...</td>\n",
       "      <td>http://www.moneynews.com/Economy/federal-reser...</td>\n",
       "      <td>Moneynews</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.moneynews.com</td>\n",
       "      <td>1394470372027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               TITLE  \\\n",
       "1  Fed official says weak data caused by weather,...   \n",
       "2  Fed's Charles Plosser sees high bar for change...   \n",
       "3  US open: Stocks fall after Fed official hints ...   \n",
       "4  Fed risks falling 'behind the curve', Charles ...   \n",
       "5  Fed's Plosser: Nasty Weather Has Curbed Job Gr...   \n",
       "\n",
       "                                                 URL          PUBLISHER  \\\n",
       "1  http://www.latimes.com/business/money/la-fi-mo...  Los Angeles Times   \n",
       "2  http://www.livemint.com/Politics/H2EvwJSK2VE6O...           Livemint   \n",
       "3  http://www.ifamagazine.com/news/us-open-stocks...       IFA Magazine   \n",
       "4  http://www.ifamagazine.com/news/fed-risks-fall...       IFA Magazine   \n",
       "5  http://www.moneynews.com/Economy/federal-reser...          Moneynews   \n",
       "\n",
       "  CATEGORY                          STORY             HOSTNAME      TIMESTAMP  \n",
       "1        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM      www.latimes.com  1394470370698  \n",
       "2        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM     www.livemint.com  1394470371207  \n",
       "3        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM  www.ifamagazine.com  1394470371550  \n",
       "4        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM  www.ifamagazine.com  1394470371793  \n",
       "5        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM    www.moneynews.com  1394470372027  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = [\"TITLE\", \"URL\", \"PUBLISHER\", \"CATEGORY\", \"STORY\", \"HOSTNAME\", \"TIMESTAMP\"]\n",
    "news_dataset = pd.read_csv(os.path.join('./data', 'newsCorpora.csv'), names=column_names, header=None, delimiter='\\t')\n",
    "news_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CATEGORY\n",
       "b    115967\n",
       "e    152469\n",
       "m     45639\n",
       "t    108344\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset.groupby(['CATEGORY']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Hosting your Algorithm in Amazon SageMaker\n",
    "# ![image](https://miro.medium.com/max/792/1*41reGFhdysmXNVHgmPMExA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building and registering the container\n",
    "\n",
    "The following shell code shows how to build the container image using `docker build` and push the container image to ECR using `docker push`. \n",
    "\n",
    "This code looks for an ECR repository in the account you're using and the current default region (if you're using a SageMaker notebook instance, this will be the region where the notebook instance was created). If the repository doesn't exist, the script will create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Stopping docker: [  OK  ]\n",
      "Starting docker:\t.[  OK  ]\n",
      "Sending build context to Docker daemon  619.7MB\n",
      "Step 1/9 : FROM 763104351884.dkr.ecr.us-west-2.amazonaws.com/tensorflow-training:1.14.0-cpu-py36-ubuntu16.04\n",
      " ---> e6a210ff54e4\n",
      "Step 2/9 : RUN apt-get update &&     apt-get install -y nginx imagemagick graphviz\n",
      " ---> Using cache\n",
      " ---> e40a0ed67524\n",
      "Step 3/9 : RUN pip install --upgrade pip\n",
      " ---> Using cache\n",
      " ---> 07d7553f52ef\n",
      "Step 4/9 : RUN pip install gevent gunicorn flask tensorflow_hub seqeval graphviz nltk spacy tqdm\n",
      " ---> Using cache\n",
      " ---> 972572e1e1e7\n",
      "Step 5/9 : RUN python -m spacy download en_core_web_sm\n",
      " ---> Using cache\n",
      " ---> a6f13b2598d1\n",
      "Step 6/9 : RUN python -m spacy download en\n",
      " ---> Using cache\n",
      " ---> 8fd6f13a470d\n",
      "Step 7/9 : ENV PATH=\"/opt/program:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 3ea40db10fc3\n",
      "Step 8/9 : COPY sagemaker_keras_text_classification /opt/program\n",
      " ---> fa48a2b8907d\n",
      "Step 9/9 : WORKDIR /opt/program\n",
      " ---> Running in 20ab9471bb0d\n",
      "Removing intermediate container 20ab9471bb0d\n",
      " ---> 9af4389842ef\n",
      "Successfully built 9af4389842ef\n",
      "Successfully tagged sagemaker-keras-text-classification:latest\n",
      "The push refers to repository [485444084140.dkr.ecr.us-west-2.amazonaws.com/sagemaker-keras-text-classification]\n",
      "060da0de3eb0: Preparing\n",
      "a4fba7e149fc: Preparing\n",
      "cd288db5ec58: Preparing\n",
      "6a35743d6767: Preparing\n",
      "7ce14b418d04: Preparing\n",
      "17414127eac6: Preparing\n",
      "cc978a7bbd2a: Preparing\n",
      "3a97a8d562fb: Preparing\n",
      "cb460459ddc8: Preparing\n",
      "b4064660a4cf: Preparing\n",
      "b6e9883adafa: Preparing\n",
      "9ee6d909e5a7: Preparing\n",
      "e722e212cbab: Preparing\n",
      "708ade65e147: Preparing\n",
      "11fc4467b8a3: Preparing\n",
      "0cf88c3675cd: Preparing\n",
      "d456742927ee: Preparing\n",
      "8722c9641a57: Preparing\n",
      "7083756ef61f: Preparing\n",
      "9d2fda619715: Preparing\n",
      "e79142719515: Preparing\n",
      "aeda103e78c9: Preparing\n",
      "2558e637fbff: Preparing\n",
      "f749b9b0fb21: Preparing\n",
      "cb460459ddc8: Waiting\n",
      "b4064660a4cf: Waiting\n",
      "b6e9883adafa: Waiting\n",
      "9ee6d909e5a7: Waiting\n",
      "e722e212cbab: Waiting\n",
      "708ade65e147: Waiting\n",
      "11fc4467b8a3: Waiting\n",
      "0cf88c3675cd: Waiting\n",
      "d456742927ee: Waiting\n",
      "8722c9641a57: Waiting\n",
      "7083756ef61f: Waiting\n",
      "9d2fda619715: Waiting\n",
      "e79142719515: Waiting\n",
      "aeda103e78c9: Waiting\n",
      "2558e637fbff: Waiting\n",
      "f749b9b0fb21: Waiting\n",
      "17414127eac6: Waiting\n",
      "cc978a7bbd2a: Waiting\n",
      "3a97a8d562fb: Waiting\n",
      "a4fba7e149fc: Layer already exists\n",
      "cd288db5ec58: Layer already exists\n",
      "6a35743d6767: Layer already exists\n",
      "7ce14b418d04: Layer already exists\n",
      "cc978a7bbd2a: Layer already exists\n",
      "cb460459ddc8: Layer already exists\n",
      "3a97a8d562fb: Layer already exists\n",
      "17414127eac6: Layer already exists\n",
      "b4064660a4cf: Layer already exists\n",
      "9ee6d909e5a7: Layer already exists\n",
      "e722e212cbab: Layer already exists\n",
      "b6e9883adafa: Layer already exists\n",
      "708ade65e147: Layer already exists\n",
      "0cf88c3675cd: Layer already exists\n",
      "d456742927ee: Layer already exists\n",
      "11fc4467b8a3: Layer already exists\n",
      "8722c9641a57: Layer already exists\n",
      "7083756ef61f: Layer already exists\n",
      "e79142719515: Layer already exists\n",
      "9d2fda619715: Layer already exists\n",
      "f749b9b0fb21: Layer already exists\n",
      "2558e637fbff: Layer already exists\n",
      "aeda103e78c9: Layer already exists\n",
      "060da0de3eb0: Pushed\n",
      "latest: digest: sha256:1e0a2b4192beb8bbc0cb23cd03fa440aee96556be69b65525fba89571eef5493 size: 5344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=sagemaker-keras-text-classification\n",
    "\n",
    "cd container\n",
    "\n",
    "chmod +x sagemaker_keras_text_classification/train\n",
    "chmod +x sagemaker_keras_text_classification/serve\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "#region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "# On a SageMaker Notebook Instance, the docker daemon may need to be restarted in order\n",
    "# to detect your network configuration correctly.  (This is a known issue.)\n",
    "if [ -d \"/home/ec2-user/SageMaker\" ]; then\n",
    "  sudo service docker restart\n",
    "fi\n",
    "\n",
    "docker build  -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have your container packaged, you can use it to train and serve models. Let's do that with the algorithm we made above.\n",
    "\n",
    "## Set up the environment\n",
    "\n",
    "Here we specify a bucket to use and the role that will be used for working with SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 prefix\n",
    "prefix = 'sagemaker-keras-text-classification'\n",
    "\n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the session\n",
    "\n",
    "The session remembers our connection parameters to SageMaker. We'll use it to perform all of our SageMaker operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "from time import gmtime, strftime\n",
    "\n",
    "sess = sage.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the data for training\n",
    "\n",
    "When training large models with huge amounts of data, you'll typically use big data tools, like Amazon Athena, AWS Glue, or Amazon EMR, to create your data in S3.  \n",
    "\n",
    "We can use use the tools provided by the SageMaker Python SDK to upload the data to a default bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIRECTORY = 'data'\n",
    "\n",
    "data_location = sess.upload_data(WORK_DIRECTORY, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an estimator and fit the model\n",
    "\n",
    "In order to use SageMaker to fit our algorithm, we'll create an `Estimator` that defines how to use the container to to train. This includes the configuration we need to invoke SageMaker training:\n",
    "\n",
    "* The __container name__. This is constucted as in the shell commands above.\n",
    "* The __role__. As defined above.\n",
    "* The __instance count__ which is the number of machines to use for training.\n",
    "* The __instance type__ which is the type of machine to use for training.\n",
    "* The __output path__ determines where the model artifact will be written.\n",
    "* The __session__ is the SageMaker session object that we defined above.\n",
    "\n",
    "Then we use fit() on the estimator to train against the data that we uploaded above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/sagemaker-keras-text-classification'.format(account, region)\n",
    "\n",
    "tree = sage.estimator.Estimator(image,\n",
    "                       role, 1, 'ml.c5.2xlarge',\n",
    "                       output_path=\"s3://{}/output\".format(sess.default_bucket()),\n",
    "                       sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-21 19:21:31 Starting - Starting the training job...\n",
      "2020-04-21 19:21:32 Starting - Launching requested ML instances...\n",
      "2020-04-21 19:22:31 Starting - Preparing the instances for training......\n",
      "2020-04-21 19:23:17 Downloading - Downloading input data...\n",
      "2020-04-21 19:23:42 Training - Downloading the training image.....\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34mStarting the training.\u001b[0m\n",
      "\u001b[34m                                               TITLE  ...      TIMESTAMP\u001b[0m\n",
      "\u001b[34m1  Fed official says weak data caused by weather,...  ...  1394470370698\u001b[0m\n",
      "\u001b[34m2  Fed's Charles Plosser sees high bar for change...  ...  1394470371207\u001b[0m\n",
      "\u001b[34m3  US open: Stocks fall after Fed official hints ...  ...  1394470371550\u001b[0m\n",
      "\u001b[34m4  Fed risks falling 'behind the curve', Charles ...  ...  1394470371793\u001b[0m\n",
      "\u001b[34m5  Fed's Plosser: Nasty Weather Has Curbed Job Gr...  ...  1394470372027\n",
      "\u001b[0m\n",
      "\u001b[34m[5 rows x 7 columns]\u001b[0m\n",
      "\n",
      "2020-04-21 19:24:37 Training - Training image download completed. Training in progress.\u001b[34mFound 65990 unique tokens.\u001b[0m\n",
      "\u001b[34mShape of data tensor: (422417, 100)\u001b[0m\n",
      "\u001b[34mShape of label tensor: (422417, 4)\u001b[0m\n",
      "\u001b[34mx_train shape:  (337933, 100)\u001b[0m\n",
      "\u001b[34mWARNING: Logging before flag parsing goes to stderr.\u001b[0m\n",
      "\u001b[34mW0421 19:25:09.561171 139745423243008 deprecation.py:506] From /usr/local/lib/python3.6/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCall initializer instance with the dtype argument instead of passing it to the constructor\u001b[0m\n",
      "\u001b[34mW0421 19:25:09.588581 139745423243008 deprecation.py:506] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCall initializer instance with the dtype argument instead of passing it to the constructor\u001b[0m\n",
      "\u001b[34mModel: \"sequential\"\u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mLayer (type)                 Output Shape              Param #   \u001b[0m\n",
      "\u001b[34m=================================================================\u001b[0m\n",
      "\u001b[34membedding (Embedding)        (None, 100, 100)          1000000   \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mflatten (Flatten)            (None, 10000)             0         \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mdense (Dense)                (None, 2)                 20002     \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mdense_1 (Dense)              (None, 4)                 12        \u001b[0m\n",
      "\u001b[34m=================================================================\u001b[0m\n",
      "\u001b[34mTotal params: 1,020,014\u001b[0m\n",
      "\u001b[34mTrainable params: 1,020,014\u001b[0m\n",
      "\u001b[34mNon-trainable params: 0\u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34m2020-04-21 19:25:09.618318: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  AVX512F\u001b[0m\n",
      "\u001b[34mTo enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2020-04-21 19:25:09.657681: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2999990000 Hz\u001b[0m\n",
      "\u001b[34m2020-04-21 19:25:09.658141: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4154fd0 executing computations on platform Host. Devices:\u001b[0m\n",
      "\u001b[34m2020-04-21 19:25:09.658163: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\u001b[0m\n",
      "\u001b[34m2020-04-21 19:25:09.659024: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\u001b[0m\n",
      "\u001b[34m2020-04-21 19:25:09.685041: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\u001b[0m\n",
      "\u001b[34mTrain on 337933 samples, validate on 84484 samples\u001b[0m\n",
      "\u001b[34mEpoch 1/5\u001b[0m\n",
      "\u001b[34m337933/337933 - 30s - loss: 0.7092 - acc: 0.7301 - val_loss: 0.6469 - val_acc: 0.7492\u001b[0m\n",
      "\u001b[34mEpoch 2/5\u001b[0m\n",
      "\u001b[34m337933/337933 - 30s - loss: 0.5830 - acc: 0.7828 - val_loss: 0.5613 - val_acc: 0.7950\u001b[0m\n",
      "\u001b[34mEpoch 3/5\u001b[0m\n",
      "\u001b[34m337933/337933 - 30s - loss: 0.5505 - acc: 0.7953 - val_loss: 0.5467 - val_acc: 0.7989\u001b[0m\n",
      "\u001b[34mEpoch 4/5\u001b[0m\n",
      "\u001b[34m337933/337933 - 30s - loss: 0.5401 - acc: 0.7987 - val_loss: 0.5431 - val_acc: 0.7998\u001b[0m\n",
      "\u001b[34mEpoch 5/5\u001b[0m\n",
      "\u001b[34m337933/337933 - 30s - loss: 0.5337 - acc: 0.8008 - val_loss: 0.5383 - val_acc: 0.8010\u001b[0m\n",
      "\u001b[34mTraining complete. Now saving model to:  /opt/ml/model\u001b[0m\n",
      "\u001b[34mW0421 19:27:40.035691 139745423243008 deprecation.py:506] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCall initializer instance with the dtype argument instead of passing it to the constructor\u001b[0m\n",
      "\u001b[34mW0421 19:27:40.036066 139745423243008 deprecation.py:506] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCall initializer instance with the dtype argument instead of passing it to the constructor\u001b[0m\n",
      "\u001b[34mTest headline:  What Improved Tech Means for Electric, Self-Driving and Flying Cars\u001b[0m\n",
      "\u001b[34mPredicted category:  t\u001b[0m\n",
      "\n",
      "2020-04-21 19:27:48 Uploading - Uploading generated training model\n",
      "2020-04-21 19:27:48 Completed - Training job completed\n",
      "Training seconds: 271\n",
      "Billable seconds: 271\n"
     ]
    }
   ],
   "source": [
    "tree.fit(data_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model\n",
    "\n",
    "Deploying the model to SageMaker hosting just requires a `deploy` call on the fitted model. This call takes an instance count, instance type, and optionally serializer and deserializer functions. These are used when the resulting predictor is created on the endpoint.\n",
    "\n",
    "__This step may take about 10-20 min__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: sagemaker-keras-text-classification-2020-04-21-19-21-31-420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import json_serializer\n",
    "predictor = tree.deploy(1, 'ml.m4.xlarge', serializer=json_serializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"result\": \"Entertainment\"}\n"
     ]
    }
   ],
   "source": [
    "request = { \"input\": \"‘Deadpool 2’ Has More Swearing, Slicing and Dicing from Ryan Reynolds\"}\n",
    "print(predictor.predict(request).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endpoint Test:\n",
    "### InvokeEndpoint using boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"result\": \"Entertainment\"}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "client = boto3.client('runtime.sagemaker')\n",
    "endpoint_name = 'sagemaker-keras-text-classification'+'-2020-04-21-19-21-31-420'\n",
    "\n",
    "payload = { \"input\": \"‘Deadpool 2’ Has More Swearing, Slicing and Dicing from Ryan Reynolds\"}\n",
    "\n",
    "response = client.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                  ContentType='application/json',\n",
    "                                  Accept='text/plain',\n",
    "                                  Body=json.dumps(payload))\n",
    "\n",
    "response_body = response['Body']\n",
    "prediction = response_body.read().decode('utf-8')\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InvokeEndpoint using AWS CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"ContentType\": \"application/json\",\n",
      "    \"InvokedProductionVariant\": \"AllTraffic\"\n",
      "}\n",
      "{\"result\": \"Business\"}"
     ]
    }
   ],
   "source": [
    "%%sh \n",
    "ENDPOINT_NAME=\"sagemaker-keras-text-classification-2020-04-21-19-21-31-420\"\n",
    "CONTENT_TYPE='application/json'\n",
    "\n",
    "aws sagemaker-runtime invoke-endpoint \\\n",
    "--endpoint-name ${ENDPOINT_NAME} \\\n",
    "--content-type ${CONTENT_TYPE} \\\n",
    "--body '{\"input\": \"Why Exercise Alone May Not Be the Key to Weight Loss\"}' prediction_response.json\n",
    "\n",
    "cat prediction_response.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional cleanup\n",
    "\n",
    "When you're done with the endpoint, you'll want to clean it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sess.delete_endpoint(predictor.endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
